# -*- coding: utf-8 -*-
"""Anime Content-Based Recommender System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b5aYcf2hI4HE2qAyCLQhX31IG_J7ohzP
"""

# Commented out IPython magic to ensure Python compatibility.
#import packages that needed

import pandas as pd
import numpy as np
from math import sqrt
import matplotlib.pyplot as plt
import seaborn as sns

sns.set_style('whitegrid')
# % matplotlib inline

from google.colab import drive
drive.mount('/content/drive')

#import the dataset used in this project

anime = pd.read_csv('/content/drive/My Drive/My Mini Projects/Recommender System/anime.csv')
rate = pd.read_csv('/content/drive/My Drive/My Mini Projects/Recommender System/rating.csv', sep = ';', error_bad_lines = False, encoding = 'latin-1')

print(anime.shape)
print(rate.shape)

"""# **Exploring Anime Dataset**"""

anime.head()

# some attributes dont seem to be required for this analysis, so can be dropped off

anime.drop(['type', 'episodes', 'rating', 'members'], axis = 1, inplace = True)

anime.dtypes

#Every genre is separated by a ',' so we simply have to call the split function on ','

anime['genre'] = anime.genre.str.split(',')
anime.head()

print(type(anime.genre))
anime.genre.isnull().sum()

#drop null rows because the data is still enough

anime = anime.dropna(axis=0)

#use one-hot-encoding to store every different genre in columns that contain either 1 or 0
#1 shows that the movie has that genre, 0 otherwise

#copying original dataset to new dataset
animeWithGenres = anime.copy()

#For every row in the dataframe, iterate through the list of genres and place a 1 into the corresponding column
for index,row in anime.iterrows():
  for genre in row['genre']:
    animeWithGenres.at[index,genre] = 1
  
#Filling in the NaN values with 0 to show that a movie doesn't have that column's genre
animeWithGenres = animeWithGenres.fillna(0)

animeWithGenres.head()

"""# **Exploring Rate Dataset**"""

rate.head()

"""# **Content Based Recommender System**"""

#user input about anime that he has watched and how he rates the anime

userInput = [
            {'name':'Fullmetal Alchemist: Brotherhood', 'rating':5},
            {'name':'Gintama', 'rating':3.5},
            {'name':'Koe no Katachi', 'rating':2},
            {'name':'Bakemonogatari', 'rating':5},
            {'name':'Nodame Cantabile Finale', 'rating':4.5}
         ] 
inputAnime = pd.DataFrame(userInput)
inputAnime

#add anime_id to userInput

#filtering out the movies by title
inputID = anime[anime['name'].isin(inputAnime.name.tolist())]

#merge anime in the form inputID & inputAnime by the title
inputAnime = pd.merge(inputID,inputAnime)

#drop the attribute that doesnt needed
inputAnime = inputAnime.drop('genre',axis=1)

inputAnime

#Filtering out the anime from the input

userAnime = animeWithGenres[animeWithGenres['anime_id'].isin(inputAnime['anime_id'].tolist())]
userAnime

#Resetting the index to avoid future issues
userAnime = userAnime.reset_index(drop=True)

#Dropping unnecessary issues due to save memory and to avoid issues
userGenreTable = userAnime.drop(['anime_id','name','genre'], 1)

userGenreTable

#dot produt to get weights

userProfile = userGenreTable.transpose().dot(inputAnime['rating'])
userProfile

#Now let's get the genres of every movie in our original dataframe
genreTable = animeWithGenres.set_index(animeWithGenres['anime_id'])

#And drop the unnecessary information
genreTable = genreTable.drop(['anime_id','name','genre'], 1)
genreTable.head()

#Multiply the genres by the weights and then take the weighted average
recommendationTable = ((genreTable*userProfile).sum(axis=1))/(userProfile.sum())
recommendationTable.head()

#Sort our recommendations in descending order
recommendationTable = recommendationTable.sort_values(ascending=False)

#Just a peek at the values
recommendationTable.head()

#The final recommendation table
anime.loc[anime['anime_id'].isin(recommendationTable.head(20).keys())]

